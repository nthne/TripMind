import json
import chromadb
import torch
import logging
from utils import get_semantic_vector
import torch
import chromadb
import logging

logger = logging.getLogger(__name__)

DB_PATH = "/Users/trannguyenmyanh/Documents/TripMind/agent/tripmind_vector_db"

def get_provinces_stats():
    """
    Thá»‘ng kÃª sá»‘ lÆ°á»£ng review vÃ  sá»‘ Ä‘á»‹a Ä‘iá»ƒm duy nháº¥t cho má»—i tá»‰nh.

        HÃ m nÃ y cháº¡y lÃºc khá»Ÿi Ä‘á»™ng, khÃ´ng liÃªn quan Ä‘áº¿n tÃ¬m kiáº¿m.
    """
    try:

        # DB_PATH pháº£i lÃ  Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i Ä‘Ã£ Ä‘á»‹nh nghÄ©a
        client = chromadb.PersistentClient(path=DB_PATH)
        target = "tripmind_reviews"


        collection = client.get_collection(name=target)
        

        # Chá»‰ láº¥y metadata Ä‘á»ƒ Ä‘áº¿m, khÃ´ng láº¥y vector/document Ä‘á»ƒ tiáº¿t kiá»‡m RAM
        results = collection.get(include=['metadatas'])
        metadatas = results.get('metadatas', [])
        
        if not metadatas:
            return {}

        stats = {}


        for meta in metadatas:

            p_id = str(meta.get('province_id', '')).zfill(2)
            d_id = meta.get('destination_id')
            

            if p_id:
                if p_id not in stats:

                    stats[p_id] = {"total_reviews": 0, "unique_places": set()}
                
                stats[p_id]["total_reviews"] += 1
                if d_id:
                    stats[p_id]["unique_places"].add(str(d_id))

        final_result = {

            pid: {
                "total_reviews": data["total_reviews"],
                "unique_places": len(data["unique_places"])
            } for pid, data in stats.items()
        }
        
        logger.info(f"âœ… Thá»‘ng kÃª xong: {len(final_result)} tá»‰nh thÃ nh.")
        return final_result

    except Exception as e:
        logger.error(f"âŒ Lá»—i khi tÃ­nh stats: {str(e)}")
        return {}
    
def ingest_to_chromadb(file_path, model, assets, device, batch_size=100):
    from utils import get_semantic_vector
    import os
    
    # 1. DÃ¹ng Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i Ä‘á»ƒ trÃ¡nh Ä‘á»c nháº§m file rÃ¡c á»Ÿ thÆ° má»¥c khÃ¡c
    client = chromadb.PersistentClient(path="/Users/trannguyenmyanh/Documents/TripMind/agent/tripmind_vector_db")
    
    try:
        client.delete_collection("tripmind_reviews")
        logger.info("â™»ï¸ ÄÃ£ xÃ³a collection cÅ© Ä‘á»ƒ lÃ m má»›i hoÃ n toÃ n")
    except:
        pass
    
    collection = client.create_collection(
        name="tripmind_reviews",
        metadata={"hnsw:space": "cosine"}
    )
    
    model.eval()
    
    # 2. Äá»c file theo dáº¡ng generator Ä‘á»ƒ tiáº¿t kiá»‡m RAM vÃ  trÃ¡nh lá»—i Ä‘á»c file
    valid_count = 0
    skipped_count = 0
    embeddings_batch, documents_batch, metadatas_batch, ids_batch = [], [], [], []
    
    # Danh sÃ¡ch kiá»ƒm tra tá»‰nh (Set nÃ y sáº½ giÃºp ta debug xem cÃ³ bao nhiÃªu tá»‰nh thá»±c táº¿)
    detected_provinces = set()

    with open(file_path, 'r', encoding='utf-8') as f:
        for idx, line in enumerate(f):
            try:
                record = json.loads(line.strip())
                text = record.get("text", "").strip()
                
                if not text or len(text) < 10:
                    skipped_count += 1
                    continue

                # Ã‰P KIá»‚U VÃ€ KIá»‚M TRA ID
                p_id = str(record.get("province_id", ""))
                d_id = str(record.get("destination_id", ""))
                
                # CÆ  CHáº¾ CHá»NG SAI Lá»†CH: 
                # ID tá»‰nh thÆ°á»ng ngáº¯n (6 sá»‘), ID Ä‘á»‹a danh thÆ°á»ng dÃ i hÆ¡n.
                # Náº¿u p_id > 7 chá»¯ sá»‘, kháº£ nÄƒng cao lÃ  dá»¯ liá»‡u bá»‹ lá»‡ch cá»™t.
                if not p_id or not d_id or len(p_id) > 7:
                    skipped_count += 1
                    continue

                detected_provinces.add(p_id)

                # 2. Xá»¬ LÃ TRIP TYPE (Giá»¯ logic cÅ© nhÆ°ng thÃªm clean data)
                trip_raw = record.get("trip", "{}")
                try:
                    trip_data = json.loads(trip_raw) if isinstance(trip_raw, str) else trip_raw
                    trip_type = trip_data.get("trip_type") if trip_data else "any"
                    trip_type = trip_type.lower().strip() if trip_type else "any"
                    if trip_type in ["", "none", "null"]: trip_type = "any"
                except:
                    trip_type = "any"

                # 3. Xá»¬ LÃ CATEGORIES
                cat_raw = record.get("categories", "[]")
                try:
                    cat_list = json.loads(cat_raw) if isinstance(cat_raw, str) else cat_raw
                    if isinstance(cat_list, list) and len(cat_list) > 0:
                        cat_id = str(cat_list[0].get('id', '0'))
                        cat_name = cat_list[0].get('name', 'ChÆ°a phÃ¢n loáº¡i')
                    else:
                        cat_id = "0"
                        cat_name = "ChÆ°a phÃ¢n loáº¡i"
                except:
                    cat_id = "0"
                    cat_name = "ChÆ°a phÃ¢n loáº¡i"

                # 4. Táº O SEMANTIC VECTOR (Sá»­ dá»¥ng assets vÃ  device Ä‘Ã£ sá»­a cho M1)
                vector = get_semantic_vector(text, model, assets, device)


                metadatas_batch.append({
                    "province_id": str(p_id).zfill(2), # Äáº¢M Báº¢O LUÃ”N LÃ€ "00", "01", "31"...
                    "destination_id": d_id,
                    "name": record.get("name", "").strip(),
                    "rating": float(record.get("rating_x", 0)),
                    "trip_type": trip_type,
                    "category": cat_name, # << THÃŠM DÃ’NG NÃ€Y Äá»‚ AGENT 1 CÃ“ THá»‚ Äá»I CHIáº¾U
                    "place_key": f"{p_id}_{d_id}"
                })
                
                embeddings_batch.append(vector)
                documents_batch.append(text)
                ids_batch.append(str(record.get("id_review", f"rev_{idx}")))
                
                valid_count += 1

                if len(embeddings_batch) >= batch_size:
                    collection.add(embeddings=embeddings_batch, documents=documents_batch, 
                                   metadatas=metadatas_batch, ids=ids_batch)
                    embeddings_batch, documents_batch, metadatas_batch, ids_batch = [], [], [], []
                
            except Exception as e:
                skipped_count += 1
                continue
    
    # Insert batch cuá»‘i
    if embeddings_batch:
        collection.add(embeddings=embeddings_batch, documents=documents_batch, 
                       metadatas=metadatas_batch, ids=ids_batch)

    logger.info(f"âœ… HoÃ n táº¥t! PhÃ¡t hiá»‡n thá»±c táº¿: {len(detected_provinces)} tá»‰nh.")
    logger.info(f"âœ… Danh sÃ¡ch ID tá»‰nh: {sorted(list(detected_provinces))}")
    return collection

def agent_1_output(
    user_query, 
    model, 
    word2idx, 
    assets, 
    device, 
    province_id, 
    trip_type='any', 
    n_places=15, 
    max_reviews_per_place=5
):
    try:
        # 1. KHá»I Táº O Káº¾T Ná»I DATABASE
        # Äáº£m báº£o Ä‘Æ°á»ng dáº«n DB_PATH Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a Ä‘Ãºng
        from database import DB_PATH 
        client = chromadb.PersistentClient(path=DB_PATH)
        collection = client.get_collection("tripmind_reviews")
        
        # 2. Lá»ŒC THEO Tá»ˆNH THÃ€NH (CHECK PROVINCE_ID FIRST)
        # Chuáº©n hÃ³a province_id thÃ nh "00", "01", "10"...
        p_id_str = str(province_id).zfill(2) 
        where_filter = {"province_id": p_id_str}
        logger.info(f"ğŸ” Agent 1 Ä‘ang tÃ¬m kiáº¿m táº¡i tá»‰nh: {p_id_str}")

        # 3. Dá»° ÄOÃN INTENT VÃ€ Táº O VECTOR (MULTI-TASK MODEL)
        model.eval()
        pred_cat_name = "KhÃ¡c" # GiÃ¡ trá»‹ máº·c Ä‘á»‹nh Ä‘á»ƒ trÃ¡nh lá»—i 'not defined'
        
        # Tiá»n xá»­ lÃ½ query tÆ°Æ¡ng tá»± utils.py (khÃ´ng dÃ¹ng format="text")
        from underthesea import word_tokenize
        tokens = word_tokenize(user_query.lower())
        indices = [word2idx.get(t, 1) for t in tokens[:100]]
        indices += [0] * (100 - len(indices))
        input_tensor = torch.LongTensor([indices]).to(device)

        with torch.no_grad():
            output = model(input_tensor)
            # Náº¿u model tráº£ vá» tuple (embedding, cat_logits)
            if isinstance(output, tuple):
                query_vector = output[0].cpu().numpy()[0].tolist()
                cat_logits = output[1]
                
                # Giáº£i mÃ£ tÃªn loáº¡i hÃ¬nh dá»± Ä‘oÃ¡n (Category Intent)
                if assets and 'cat_encoder' in assets:
                    pred_cat_idx = torch.argmax(cat_logits, dim=1).item()
                    pred_cat_name = assets['cat_encoder'].inverse_transform([pred_cat_idx])[0]
                    print(f"ğŸ”® Há»‡ thá»‘ng dá»± Ä‘oÃ¡n báº¡n Ä‘ang tÃ¬m: {pred_cat_name}")
            else:
                query_vector = output.cpu().numpy()[0].tolist()

        # 4. TRUY Váº¤N VECTOR DATABASE Vá»šI Bá»˜ Lá»ŒC Cá»¨NG
        # Sá»­ dá»¥ng rich query báº±ng cÃ¡ch káº¿t há»£p intent vÃ o cÃ¢u tÃ¬m kiáº¿m
        rich_query = f"{user_query} {pred_cat_name}".lower()
        # Táº¡o vector tá»« rich_query Ä‘á»ƒ khá»›p vá»›i logic ingest (name + text)
        final_query_vector = get_semantic_vector(rich_query, model, word2idx, device)

        results = collection.query(
            query_embeddings=[final_query_vector],
            n_results=100, # Láº¥y táº­p á»©ng viÃªn rá»™ng Ä‘á»ƒ re-rank
            where=where_filter # Lá»ŒC Tá»ˆNH TRÆ¯á»šC Táº I ÄÃ‚Y
        )

        if not results['documents'] or not results['documents'][0]:
            return []

        # 5. GOM NHÃ“M Äá»ŠA DANH & RE-RANKING (TIÃŠU CHÃ PHá»¤)
        places_dict = {}
        docs = results['documents'][0]
        metas = results['metadatas'][0]
        dists = results['distances'][0]

        target_trip_type = trip_type.lower().strip()

        for i in range(len(docs)):
            meta = metas[i]
            d_id = str(meta.get("destination_id", f"unknown_{i}"))
            db_cat_name = meta.get("category", "KhÃ¡c")
            db_trip_type = str(meta.get("trip_type", "any")).lower()
            
            # TÃ­nh Ä‘iá»ƒm (Khoáº£ng cÃ¡ch tháº¥p hÆ¡n lÃ  tá»‘t hÆ¡n)
            final_score = dists[i]
            
            # Bonus 1: Khá»›p loáº¡i hÃ¬nh Ä‘á»‹a danh dá»± Ä‘oÃ¡n (-0.15)
            if db_cat_name == pred_cat_name and pred_cat_name != "KhÃ¡c":
                final_score -= 0.15

            # Bonus 2: Khá»›p Ä‘á»‘i tÆ°á»£ng Ä‘i cÃ¹ng (trip_type) (-0.10)
            if target_trip_type != "any" and db_trip_type == target_trip_type:
                final_score -= 0.10

            # Gom nhÃ³m review theo tá»«ng Ä‘á»‹a Ä‘iá»ƒm duy nháº¥t
            if d_id not in places_dict:
                places_dict[d_id] = {
                    "destination_id": d_id,
                    "name": meta.get("name", "Äá»‹a danh chÆ°a xÃ¡c Ä‘á»‹nh"),
                    "category": db_cat_name,
                    "trip_type": db_trip_type,
                    "reviews": [docs[i]],
                    "min_score": final_score
                }
            else:
                if len(places_dict[d_id]["reviews"]) < max_reviews_per_place:
                    places_dict[d_id]["reviews"].append(docs[i])
                if final_score < places_dict[d_id]["min_score"]:
                    places_dict[d_id]["min_score"] = final_score

        # 6. TRáº¢ Vá»€ 15 Káº¾T QUáº¢ Tá»T NHáº¤T
        sorted_places = sorted(places_dict.values(), key=lambda x: x['min_score'])
        final_output = sorted_places[:n_places]

        print(f"âœ… Xá»­ lÃ½ xong: TrÃ­ch xuáº¥t Ä‘Æ°á»£c {len(final_output)} Ä‘á»‹a danh hÃ ng Ä‘áº§u.")
        return final_output

    except Exception as e:
        logger.error(f"âŒ Lá»—i Agent 1: {str(e)}")
        import traceback
        traceback.print_exc()
        return []